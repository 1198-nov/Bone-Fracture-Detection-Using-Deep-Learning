# -*- coding: utf-8 -*-
"""bone_fracture_detection (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13AtTcDP3bNxmZwgNjKamXXQK33M9SN0l
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, models, transforms
from sklearn.metrics import confusion_matrix, accuracy_score
import torch.nn.init as init

import os
import random
import cv2
import shutil
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from PIL import Image
import seaborn as sns
import math

def create_dirs(splits, class_directories, output_dir):
    os.makedirs(output_dir, exist_ok = True)
    for split in splits:
        for class_dir in class_directories:
            os.makedirs(os.path.join(output_dir, split, class_dir), exist_ok=True)

# Extracting class ID from label files

def extract_class_labels(label_content):
    class_ids = set()
    lines = label_content.strip().split('\n')

    for line in lines:
        if line.strip():
            parts = line.split()
            if len(parts) > 0:
                try:
                    class_id = int(parts[0])
                    class_ids.add(class_id)
                except ValueError:
                    pass
                    #print(f"Skipping invalid line: {line}")
    return class_ids

# Reading the label file content and passes it to 'extract_class_labels()'

def extract_class_labels_from_file(file_path):
    # Read label content
    with open(file_path, 'r') as file:
        label_content = file.read()
    # Extract class IDs
    return extract_class_labels(label_content)

def move_image_to_class_folder(image_path, class_ids, split, operation=None):
    for class_id in class_ids:
        class_folder = class_directories[class_id]
        output_path = os.path.join(output_dir, split, class_folder)
        os.makedirs(output_path, exist_ok=True)

        dest_image_path = os.path.join(output_path, os.path.basename(image_path))

        if os.path.exists(image_path):
            if operation:
                image = Image.open(image_path)
                processed_image = operation(image)
                processed_image.save(dest_image_path)
            else:
                shutil.copy(image_path, dest_image_path)


def move_images_unsorted(base_dir, output_path, operation=None):
    count = 0
    for split in splits:
        labels_dir = os.path.join(base_dir, split, 'labels')
        images_dir = os.path.join(base_dir, split, 'images')

        for label_file in os.listdir(labels_dir):
            if label_file.endswith('.txt'):
                label_file_path = os.path.join(labels_dir, label_file)
                image_file = label_file.replace('.txt', '.jpg')
                image_path = os.path.join(images_dir, image_file)

                class_ids = extract_class_labels_from_file(label_file_path)

                if class_ids:
                    move_image_to_class_folder(image_path, class_ids, split, operation=operation)
                    count += 1
    print(f"Moved {count} images")

def move_images_sortedAfterOperation(base_dir, output_path, operation=None):
    count = 0
    for split in os.listdir(base_dir):
        #print(split)
        for label in os.listdir(os.path.join(base_dir, split)):
            #print(label)
            input_path = os.path.join(base_dir, split, label)
            for image_path in os.listdir(input_path):
                image = Image.open(os.path.join(input_path, image_path))
                if operation:
                    modified_image = operation(image)
                else:
                    modified_image = image
                save_path = os.path.join(output_path, split, label, image_path)
                modified_image.save(save_path)

### Visualize random images from the train dataset
def display_random_first_images_each_categories(directory, split='train', titleForPSNR = None, PSNR = 'Not calculated'):
    fig, axes = plt.subplots(1, 6 , figsize=(20, 5))
    if titleForPSNR:
        fig.suptitle(f'first images in {titleForPSNR} filtering are with average PSNR {PSNR}')
    else:
        fig.suptitle(f'first images in {split} directory')

    images = []

    for category in os.listdir(os.path.join(directory, split)):
        image_path= os.path.join(directory, split, category)
        for image in os.listdir(image_path):
            image = Image.open(os.path.join(image_path, image))
            images.append((image, category))
            break
    for i in range(6):
        axes[i].imshow(images[i][0], cmap='gray')
        axes[i].axis('off')
        axes[i].set_title(images[i][1])
    plt.show()

"""Image comparison for quality."""

def compare_original_and_processed_images(processed_dir, operation, original_dir='/kaggle/working/imageResize224*224'):
    metric_sum = 0
    count = 0

    for split in os.listdir(original_dir):
        for label in os.listdir(os.path.join(original_dir, split)):
            original_path = os.path.join(original_dir, split, label)
            processed_path = os.path.join(processed_dir, split, label)

            for image_file in os.listdir(original_path):
                original_image_path = os.path.join(original_path, image_file)
                processed_image_path = os.path.join(processed_path, image_file)

                if not os.path.exists(processed_image_path):
                    print(f"Processed image not found: {processed_image_path}")
                    continue

                try:
                    original = Image.open(original_image_path).convert('L')
                    processed = Image.open(processed_image_path).convert('L')

                    original_np = np.array(original)
                    processed_np = np.array(processed)

                    metric_value = operation(original_np, processed_np)
                    metric_sum += metric_value
                    count += 1

                except Exception as e:
                    print(f"Error processing {image_file}: {e}")

    average_metric = metric_sum / count if count > 0 else 0
    return round(average_metric, 2)


def psnr(img1, img2):
    mse = np.mean((img1 - img2) ** 2)
    if mse == 0:
        return float('inf')
    PIXEL_MAX = 255.0
    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))

input_dir = '/kaggle/input/bone-fracture-detection-computer-vision-project/BoneFractureYolo8/train'
print(os.listdir(input_dir))

# path to used directories
base_dir = '/kaggle/input/bone-fracture-detection-computer-vision-project/BoneFractureYolo8'

output_dir = '/kaggle/working/sortedDB_original'

# List of class directories
class_directories = ['elbow_positive', 'fingers_positive', 'forearm_fracture', 'humerus_fracture',
                     'humerus', 'shoulder_fracture', 'wrist_positive']

# Dataset splits (train, valid, test)
splits = ['train', 'valid', 'test']

create_dirs(splits, class_directories, output_dir)
move_images_unsorted(base_dir, output_dir)

"""### Plot bar graph to see number of images for each class to check data imbalance"""

for split in splits:
    image_count = []

    for class_dir in class_directories:
        class_path = os.path.join(output_dir, split, class_dir)

        no_of_images = 0
        for image in os.listdir(class_path):
            if image.endswith(('.jpg', '.png')):
                no_of_images += 1
        image_count.append(no_of_images)

    # Create the bar graph
    bars = plt.barh(class_directories, image_count)

    # Add labels and title
    plt.xlabel('Number of Images')
    plt.ylabel('Classes')
    plt.title(f'Bar Graph : Number of Images for each Class in {split} split')

    # Add image_count value on each bar
    for bar in bars:
        width = bar.get_width()
        plt.text(width + 10, bar.get_y() + bar.get_height() / 2, str(width),
                 va='center', ha='left', fontsize=10)

    # Display the graph
    plt.show()

"""#Removing empty directories"""

import os
import shutil

dir_path = '/kaggle/working/sortedDB_original/train/humerus_fracture'

if os.path.exists(dir_path):
    shutil.rmtree(dir_path)
    print(f"Directory {dir_path} and all its contents have been deleted.")
else:
    print(f"Directory {dir_path} does not exist.")



dir_path = '/kaggle/working/sortedDB_original/valid/humerus_fracture'

if os.path.exists(dir_path) and not os.listdir(dir_path):
    os.rmdir(dir_path)
    print(f"Directory {dir_path} deleted.")
else:
    print(f"Directory {dir_path} is not empty or does not exist.")


dir_path = '/kaggle/working/sortedDB_original/test/humerus_fracture'

if os.path.exists(dir_path) and not os.listdir(dir_path):
    os.rmdir(dir_path)
    print(f"Directory {dir_path} deleted.")
else:
    print(f"Directory {dir_path} is not empty or does not exist.")

"""Resizing in sorted DB & 224*224 storing them in ."""

class_directories = ['elbow_positive', 'fingers_positive', 'forearm_fracture',
                     'humerus', 'shoulder_fracture', 'wrist_positive']

def resize224(image):
    return image.resize((224, 224))

create_dirs(splits, class_directories, "/kaggle/working/imageResize224*224")
move_images_sortedAfterOperation(output_dir, "/kaggle/working/imageResize224*224", resize224)
display_random_first_images_each_categories("/kaggle/working/imageResize224*224", split='train')

display_random_first_images_each_categories("/kaggle/working/sortedDB_original")

# 2. CLAHE (on grayscale)
def clahe_filter(image):
    image = image.convert('L')
    img_np = np.array(image)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(img_np)
    return Image.fromarray(enhanced).resize((224, 224))

# 3. Median Filter
def median_filter(image):
    image = image.convert('L')
    img_np = np.array(image)
    filtered = cv2.medianBlur(img_np, 3)
    return Image.fromarray(filtered).resize((224, 224))

# 4. Bilateral Filter
def bilateral_filter(image):
    image = image.convert('L')
    img_np = np.array(image)
    filtered = cv2.bilateralFilter(img_np, d=9, sigmaColor=75, sigmaSpace=75)
    return Image.fromarray(filtered).resize((224, 224))

# 5. CLAHE + Median Filter
def clahe_median_filter(image):
    image = image.convert('L')
    img_np = np.array(image)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(img_np)
    medianed = cv2.medianBlur(enhanced, 3)
    return Image.fromarray(medianed).resize((224, 224))

# CLAHE
create_dirs(splits, class_directories, "/kaggle/working/clahe_filtered")
move_images_sortedAfterOperation(output_dir, "/kaggle/working/clahe_filtered", clahe_filter)

# Median Filter
create_dirs(splits, class_directories, "/kaggle/working/median_filtered")
move_images_sortedAfterOperation(output_dir, "/kaggle/working/median_filtered", median_filter)

# Bilateral Filter
create_dirs(splits, class_directories, "/kaggle/working/bilateral_filtered")
move_images_sortedAfterOperation(output_dir, "/kaggle/working/bilateral_filtered", bilateral_filter)

# CLAHE + Median Filter (Bonus)
create_dirs(splits, class_directories, "/kaggle/working/clahe_median_filtered")
move_images_sortedAfterOperation(output_dir, "/kaggle/working/clahe_median_filtered", clahe_median_filter)

"""PSNR: It quantifies how much noise or distortion has been introduced.

PSNR Value (in dB)	Interpretation
> 40 dB	Excellent quality (almost identical)
30–40 dB	Good quality
20–30 dB	Acceptable / Noticeable distortion
< 20 dB	Poor quality / Significant loss
"""

display_random_first_images_each_categories("/kaggle/working/imageResize224*224", split='train')

#CLAHE
PSNR_clahe = compare_original_and_processed_images(processed_dir = "/kaggle/working/clahe_filtered" , operation = psnr)
display_random_first_images_each_categories("/kaggle/working/clahe_filtered", split='train', titleForPSNR = 'CLAHE', PSNR = PSNR_clahe)

#Median
PSNR_Median = compare_original_and_processed_images(processed_dir = "/kaggle/working/median_filtered", operation = psnr)
display_random_first_images_each_categories("/kaggle/working/median_filtered", split='train', titleForPSNR = 'median', PSNR = PSNR_Median)

PSNR_bilateral = compare_original_and_processed_images(processed_dir = "/kaggle/working/bilateral_filtered", operation = psnr)
display_random_first_images_each_categories("/kaggle/working/bilateral_filtered", split='train', titleForPSNR = 'bilateral', PSNR = PSNR_bilateral)

PSNR_clahe_median = compare_original_and_processed_images(processed_dir = "/kaggle/working/clahe_median_filtered", operation = psnr)
display_random_first_images_each_categories("/kaggle/working/clahe_median_filtered", split='train', titleForPSNR = 'CLAHE & Median', PSNR = PSNR_clahe_median)

"""### Preprocessing: Normalization & Scaling"""

mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]

data_transforms = {
    'train': transforms.Compose([
        #transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ]),
    'valid': transforms.Compose([
        #transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ]),
    'test': transforms.Compose([
        #transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ]),
}

"""### Load the dataset"""

# Load the datasets
train_dataset = datasets.ImageFolder('/kaggle/working/imageResize224*224', transform=data_transforms['train'])
valid_dataset = datasets.ImageFolder('/kaggle/working/imageResize224*224', transform=data_transforms['valid'])
test_dataset = datasets.ImageFolder('/kaggle/working/imageResize224*224', transform=data_transforms['test'])

# Create data loaders
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# set the device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

#EPOCHS = 15
DROPOUT_PROB = 0.3
WEIGHT_DECAY = 0.01
LEARNING_RATE = 0.01
SCHEDULER_STEP_SIZE = 5
GAMMA = 0.01

"""## Define and Create CNN Model"""

num_classes = len(train_dataset.classes)

# Define CNN Architecture
class CNNModel(nn.Module):
  def __init__(self):
    super(CNNModel, self).__init__()

    self.conv_layer_1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
    self.conv_layer_2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
    self.conv_layer_3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
    self.conv_layer_4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)

    self.batch_norm_1 = nn.BatchNorm2d(32)
    self.batch_norm_2 = nn.BatchNorm2d(64)
    self.batch_norm_3 = nn.BatchNorm2d(128)
    self.batch_norm_4 = nn.BatchNorm2d(256)

    self.dropout = nn.Dropout(DROPOUT_PROB)

    self.max_pool = nn.MaxPool2d(2, 2)

    self.activation_function = nn.ReLU()

    self.linear_layer_1 = nn.Linear(256 * 14 * 14, 1024)
    self.linear_layer_output = nn.Linear(1024, num_classes)

    self.initialize_weights()

  def initialize_weights(self):
    init.kaiming_uniform_(self.conv_layer_1.weight, mode='fan_out', nonlinearity='relu')
    init.kaiming_uniform_(self.conv_layer_2.weight, mode='fan_out', nonlinearity='relu')
    init.kaiming_uniform_(self.conv_layer_3.weight, mode='fan_out', nonlinearity='relu')
    init.kaiming_uniform_(self.conv_layer_4.weight, mode='fan_out', nonlinearity='relu')

    init.kaiming_uniform_(self.linear_layer_1.weight, mode='fan_out', nonlinearity='relu')
    init.kaiming_uniform_(self.linear_layer_output.weight, mode='fan_out', nonlinearity='relu')

    if self.conv_layer_1.bias is not None:
      init.zeros_(self.conv_layer_1.bias)
    if self.conv_layer_2.bias is not None:
      init.zeros_(self.conv_layer_2.bias)
    if self.conv_layer_3.bias is not None:
      init.zeros_(self.conv_layer_3.bias)
    if self.conv_layer_4.bias is not None:
      init.zeros_(self.conv_layer_4.bias)

    if self.linear_layer_1.bias is not None:
      init.zeros_(self.linear_layer_1.bias)
    if self.linear_layer_output.bias is not None:
      init.zeros_(self.linear_layer_output.bias)


  def forward(self, x):
    x = self.max_pool(self.activation_function(self.batch_norm_1(self.conv_layer_1(x))))
    x = self.max_pool(self.dropout(self.activation_function(self.batch_norm_2(self.conv_layer_2(x)))))
    x = self.max_pool(self.activation_function(self.batch_norm_3(self.conv_layer_3(x))))
    x = self.max_pool(self.dropout(self.activation_function(self.batch_norm_4(self.conv_layer_4(x)))))

    x = x.view(-1, 256 * 14 * 14)

    x = self.dropout(self.activation_function(self.linear_layer_1(x)))
    x = self.linear_layer_output(x)

    return x


cnn_model = CNNModel()
cnn_model = cnn_model.to(device)
print(cnn_model)

"""## Load & Modify ResNet Model

## Model Training

## Evaluation
"""

import os
import torch
import torch.nn as nn
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from tqdm import tqdm

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Mean and standard deviation for normalization
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]

data_transforms = {
    'train': transforms.Compose([
        #transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ]),
    'valid': transforms.Compose([
        #transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ]),
    'test': transforms.Compose([
        #transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ]),
}

def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=20):
    train_acc = []
    val_acc = []
    train_losses = []
    val_losses = []

    for epoch in range(num_epochs):
        model.train()
        correct = 0
        total = 0
        running_loss = 0.0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * labels.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        epoch_loss = running_loss / total
        train_losses.append(epoch_loss)
        train_acc.append(100 * correct / total)

        # Validation
        model.eval()
        correct = 0
        total = 0
        val_running_loss = 0.0
        with torch.no_grad():
            for images, labels in valid_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)

                val_running_loss += loss.item() * labels.size(0)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        val_epoch_loss = val_running_loss / total
        val_losses.append(val_epoch_loss)
        val_acc.append(100 * correct / total)

    return train_acc, val_acc, train_losses, val_losses


# Training Function
def train_model_CNN(model, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=20):
  best_acc = 0.0
  # print(device)

  train_losses = []
  train_accuracies = []
  val_losses = []
  val_accuracies = []

  for epoch in range(num_epochs):
    print(f'Epoch {epoch+1}/{num_epochs} : ', end='')

    model.train()
    running_loss = 0.0
    running_corrects = 0

    for inputs, labels in train_loader:
      inputs, labels = inputs.to(device), labels.to(device)

      optimizer.zero_grad()

      outputs = model(inputs)
      loss = criterion(outputs, labels)
      _, preds = torch.max(outputs, 1)

      loss.backward()
      optimizer.step()

      running_loss += loss.item() * inputs.size(0)
      running_corrects += torch.sum(preds == labels.data)

    #scheduler.step()

    epoch_loss = running_loss / len(train_loader.dataset)
    epoch_acc = 100 * running_corrects.double() / len(train_loader.dataset)

    print(f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} %;   ', end='')

    train_losses.append(epoch_loss)
    train_accuracies.append(epoch_acc.item())  # ✅ Fix

    model.eval()
    val_running_loss = 0.0
    val_running_corrects = 0

    with torch.no_grad():
      for inputs, labels in valid_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        outputs = model(inputs)
        loss = criterion(outputs, labels)

        _, preds = torch.max(outputs, 1)

        val_running_loss += loss.item() * inputs.size(0)
        val_running_corrects += torch.sum(preds == labels.data)

    val_loss = val_running_loss / len(valid_loader.dataset)
    val_acc = 100 * val_running_corrects.double() / len(valid_loader.dataset)

    print(f'Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f} %')

    val_losses.append(val_loss)
    val_accuracies.append(val_acc.item())  # ✅ Fix

    if isinstance(model, CNNModel):
      best_model_path = 'best_cnn_model.pth'
    else:
      best_model_path = 'best_resnet_model.pth'

    if val_acc > best_acc:
        best_acc = val_acc
        torch.save(model.state_dict(), best_model_path)

  print(f'Best Validation Accuracy: {best_acc:.4f}')

  return train_accuracies, val_accuracies, train_losses, val_losses

def evaluate_model(model, test_loader):
    model.eval()
    y_true = []
    y_pred = []

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(predicted.cpu().numpy())

    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)
    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)
    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)

    return accuracy, precision, recall, f1, y_true, y_pred

def plot_confusion_matrix(y_true, y_pred, class_names, title="Confusion Matrix"):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=class_names, yticklabels=class_names)
    plt.title(title)
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.show()

import torch
import torchvision.models as models
from torchvision.models import (
    vgg16,
    resnet18,
    densenet121,
    efficientnet_b0
)


model_vgg16 = vgg16(pretrained=True)
model_resnet18 = resnet18(pretrained=True)
model_densenet121 = densenet121(pretrained=True)
model_efficientnet_b0 = efficientnet_b0(pretrained=True)

num_classes = 6  # change based on your dataset

# Modify VGG16
model_vgg16.classifier[6] = torch.nn.Linear(model_vgg16.classifier[6].in_features, num_classes)

# Modify ResNet-18
model_resnet18.fc = torch.nn.Linear(model_resnet18.fc.in_features, num_classes)

# Modify DenseNet121
model_densenet121.classifier = torch.nn.Linear(model_densenet121.classifier.in_features, num_classes)

# Modify EfficientNet-B0
model_efficientnet_b0.classifier[1] = torch.nn.Linear(model_efficientnet_b0.classifier[1].in_features, num_classes)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device, "is the device")

model_vgg16 = model_vgg16.to(device)
model_resnet18 = model_resnet18.to(device)
model_densenet121 = model_densenet121.to(device)
model_efficientnet_b0 = model_efficientnet_b0.to(device)
CNN_model = CNNModel()

pretrained_models = [CNN_model, model_vgg16, model_resnet18, model_densenet121, model_efficientnet_b0]

results = []

model_directory = '/kaggle/working/models'
os.makedirs(model_directory, exist_ok = True)

datasetDirs = ['bilateral_filtered', 'clahe_filtered', 'clahe_median_filtered', 'imageResize224*224', 'median_filtered']

for filt in os.listdir('/kaggle/working/'):
    if filt not in datasetDirs:
        continue
    os.makedirs(os.path.join(model_directory, filt), exist_ok = True)
    data_path = os.path.join('/kaggle/working/', filt)
    if not os.path.isdir(data_path): continue
    print(f" Processing Filtered Dataset: {filt}")

    # Load dataset
    train_dataset = datasets.ImageFolder(os.path.join(data_path, 'train'), transform=data_transforms['train'])
    valid_dataset = datasets.ImageFolder(os.path.join(data_path, 'valid'), transform=data_transforms['valid'])
    test_dataset  = datasets.ImageFolder(os.path.join(data_path, 'test'),  transform=data_transforms['test'])

    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)
    test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)

    for model in pretrained_models:
        name = model.__class__.__name__
        print(f"Training model: {name} on {filt}")

        os.makedirs(os.path.join(model_directory, filt, name), exist_ok = True)

        model_copy = model
        model_copy = model_copy.to(device)
        criterion = nn.CrossEntropyLoss()

        if isinstance(model, CNNModel):
            optimizer = torch.optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)
            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=SCHEDULER_STEP_SIZE, gamma=GAMMA)
            train_acc, val_acc, train_loss, val_loss = train_model_CNN(model_copy, train_loader, valid_loader, criterion, optimizer, scheduler, num_epochs=20)
        else:
            optimizer = torch.optim.Adam(model_copy.parameters(), lr=1e-4)
            train_acc, val_acc, train_loss, val_loss = train_model(model_copy, train_loader, valid_loader, criterion, optimizer)

        # Plot Accuracy Curve
        plt.plot(train_acc, label='Train Accuracy')
        plt.plot(val_acc, label='Validation Accuracy')
        plt.title(f'{name} Accuracy on {filt}')
        plt.xlabel("Epoch")
        plt.ylabel("Accuracy (%)")
        plt.legend()
        plt.show()

        # Plot loss Curve
        plt.plot(train_loss, label='Train loss')
        plt.plot(val_loss, label='Validation loss')
        plt.title(f'{name} loss on {filt}')
        plt.xlabel("Epoch")
        plt.ylabel("loss (%)")
        plt.legend()
        plt.show()

        # Final test set evaluation
        acc, prec, rec, f1, y_true, y_pred = evaluate_model(model_copy, test_loader)
        results.append([name, filt, acc, prec, rec, f1])

        # Confusion matrix
        class_names = train_dataset.classes  # assumes same classes across splits
        plot_confusion_matrix(y_true, y_pred, class_names, title=f"{name} on {filt}")


        model_save_path = os.path.join(model_directory, filt, name, f"{filt}_weights.pth")
        torch.save(model_copy.state_dict(), model_save_path)

        print("----------------------------------------------------------------------------------------------------")
        print("----------------------------------------------------------------------------------------------------")
        print("----------------------------------------------------------------------------------------------------")

results_df = pd.DataFrame(results, columns=["Model", "Filter", "Accuracy", "Precision", "Recall", "F1-Score"])
print(results_df)
results_df.to_csv("/kaggle/working/benchmark_results.csv", index=False)